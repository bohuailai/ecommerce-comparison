"""
GitHub è³‡æ–™åº«åŒæ­¥æ¨¡çµ„
å¾ GitHub å€‰åº«ä¸‹è¼‰æœ€æ–°çš„è³‡æ–™åº«æª”æ¡ˆ
"""

import os
import requests
import shutil
from datetime import datetime
import sqlite3
import tempfile

def download_latest_database(github_username="yolok9453", repo_name="crawls-web", branch="master"):
    """
    å¾ GitHub ä¸‹è¼‰æœ€æ–°çš„è³‡æ–™åº«æª”æ¡ˆ
    """
    try:
        # GitHub raw file URL
        db_url = f"https://raw.githubusercontent.com/{github_username}/{repo_name}/{branch}/data/crawler_data.db"
        
        # æœ¬åœ°è³‡æ–™åº«è·¯å¾‘
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        local_db_path = os.path.join(project_root, 'data', 'crawler_data.db')
        backup_db_path = os.path.join(project_root, 'data', f'crawler_data_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.db')
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        os.makedirs(os.path.dirname(local_db_path), exist_ok=True)
        
        print(f"ğŸ”„ æ­£åœ¨å¾ GitHub ä¸‹è¼‰æœ€æ–°è³‡æ–™åº«...")
        print(f"ğŸ“¥ ä¸‹è¼‰ç¶²å€: {db_url}")
        
        # ä¸‹è¼‰æª”æ¡ˆ
        response = requests.get(db_url, timeout=30)
        response.raise_for_status()
        
        # å‚™ä»½ç¾æœ‰è³‡æ–™åº«ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists(local_db_path):
            shutil.copy2(local_db_path, backup_db_path)
            print(f"ğŸ’¾ å·²å‚™ä»½ç¾æœ‰è³‡æ–™åº«åˆ°: {backup_db_path}")
        
        # å„²å­˜æ–°è³‡æ–™åº«
        with open(local_db_path, 'wb') as f:
            f.write(response.content)
        
        print(f"âœ… æˆåŠŸä¸‹è¼‰è³‡æ–™åº«åˆ°: {local_db_path}")
        print(f"ğŸ“Š æª”æ¡ˆå¤§å°: {len(response.content)} bytes")
        
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•— - ç¶²è·¯éŒ¯èª¤: {e}")
        return False
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•— - å…¶ä»–éŒ¯èª¤: {e}")
        return False

def check_database_update_time():
    """
    æª¢æŸ¥æœ¬åœ°è³‡æ–™åº«çš„æœ€å¾Œæ›´æ–°æ™‚é–“
    """
    try:
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        local_db_path = os.path.join(project_root, 'data', 'crawler_data.db')
        
        if os.path.exists(local_db_path):
            mtime = os.path.getmtime(local_db_path)
            update_time = datetime.fromtimestamp(mtime)
            print(f"ğŸ“… æœ¬åœ°è³‡æ–™åº«æœ€å¾Œæ›´æ–°æ™‚é–“: {update_time.strftime('%Y-%m-%d %H:%M:%S')}")
            return update_time
        else:
            print("âŒ æœ¬åœ°è³‡æ–™åº«ä¸å­˜åœ¨")
            return None
    except Exception as e:
        print(f"âŒ æª¢æŸ¥è³‡æ–™åº«æ›´æ–°æ™‚é–“å¤±æ•—: {e}")
        return None

def auto_sync_if_needed(max_age_hours=1):
    """
    å¦‚æœæœ¬åœ°è³‡æ–™åº«å¤ªèˆŠï¼Œè‡ªå‹•åŒæ­¥
    è¿”å› True å¦‚æœæœ‰ä¸‹è¼‰æ›´æ–°ï¼ŒFalse å¦‚æœä¸éœ€è¦æ›´æ–°
    """
    try:
        update_time = check_database_update_time()
        
        if update_time is None:
            print("ğŸ”„ æœ¬åœ°è³‡æ–™åº«ä¸å­˜åœ¨ï¼Œé–‹å§‹ä¸‹è¼‰...")
            return download_latest_database()
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        now = datetime.now()
        age_hours = (now - update_time).total_seconds() / 3600
        
        if age_hours > max_age_hours:
            print(f"ğŸ”„ æœ¬åœ°è³‡æ–™åº«å·² {age_hours:.1f} å°æ™‚æœªæ›´æ–°ï¼Œé–‹å§‹åŒæ­¥...")
            return download_latest_database()
        else:
            print(f"âœ… æœ¬åœ°è³‡æ–™åº«å¤ æ–°ï¼ˆ{age_hours:.1f} å°æ™‚å‰ï¼‰ï¼Œç„¡éœ€åŒæ­¥")
            return False
            
    except Exception as e:
        print(f"âŒ è‡ªå‹•åŒæ­¥æª¢æŸ¥å¤±æ•—: {e}")
        return False


def download_latest_daily_deals_db(github_username="yolok9453", repo_name="crawls-web", branch="master"):
    """
    ä¸‹è¼‰ GitHub ä¸Šçš„è³‡æ–™åº«æª”æ¡ˆåˆ°æš«å­˜ä¸¦å›å‚³æš«å­˜æª”è·¯å¾‘ï¼ˆåªç”¨æ–¼æ“·å– daily_dealsï¼‰ã€‚
    è¿”å›æš«å­˜æª”è·¯å¾‘æˆ– Noneï¼ˆå¤±æ•—ï¼‰ã€‚
    """
    try:
        db_url = f"https://raw.githubusercontent.com/{github_username}/{repo_name}/{branch}/data/crawler_data.db"
        print(f"ğŸ”„ æ­£åœ¨å¾ GitHub ä¸‹è¼‰è³‡æ–™åº«ï¼ˆåƒ…ç”¨æ–¼ daily_dealsï¼‰: {db_url}")

        response = requests.get(db_url, timeout=30)
        response.raise_for_status()

        fd, tmp_path = tempfile.mkstemp(prefix="crawler_data_", suffix=".db")
        os.close(fd)
        with open(tmp_path, 'wb') as f:
            f.write(response.content)

        print(f"âœ… ä¸‹è¼‰å®Œæˆï¼Œæš«å­˜æª”: {tmp_path}")
        return tmp_path
    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•— - ç¶²è·¯éŒ¯èª¤: {e}")
        return None
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•— - å…¶ä»–éŒ¯èª¤: {e}")
        return None


def sync_daily_deals_from_remote_db(remote_db_path, local_db_path=None, backup=True):
    """
    å°‡é ç«¯è³‡æ–™åº«çš„ daily_deals è¡¨åŒæ­¥åˆ°æœ¬åœ°è³‡æ–™åº«ã€‚
    - æœƒå‚™ä»½æœ¬åœ°è³‡æ–™åº«æª”æ¡ˆï¼ˆè‹¥ backup=True ä¸”æª”æ¡ˆå­˜åœ¨ï¼‰
    - åŒæ­¥ç­–ç•¥ï¼šåˆªé™¤ local.daily_deals å…¨éƒ¨å…§å®¹ï¼Œç„¶å¾Œå¾ remote.daily_deals åŒ¯å…¥ï¼ˆç°¡æ½”ä¸”å¯ä¿è­‰ä¸€è‡´æ€§ï¼‰
    è¿”å› True/False
    """
    try:
        if local_db_path is None:
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            local_db_path = os.path.join(project_root, 'data', 'crawler_data.db')

        if not os.path.exists(remote_db_path):
            print(f"âŒ é ç«¯æš«å­˜æª”ä¸å­˜åœ¨: {remote_db_path}")
            return False

        # å‚™ä»½æœ¬åœ°è³‡æ–™åº«
        if backup and os.path.exists(local_db_path):
            backup_db_path = os.path.join(os.path.dirname(local_db_path), f'crawler_data_daily_deals_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.db')
            shutil.copy2(local_db_path, backup_db_path)
            print(f"ğŸ’¾ å·²å‚™ä»½æœ¬åœ°è³‡æ–™åº«åˆ°: {backup_db_path}")

        # ä½¿ç”¨ sqlite3 attach æ–¹å¼é€²è¡ŒåŒæ­¥
        conn = sqlite3.connect(local_db_path)
        cursor = conn.cursor()

        cursor.execute("ATTACH DATABASE ? AS remote_db", (remote_db_path,))

        # æª¢æŸ¥ remote æ˜¯å¦æœ‰ daily_deals
        cursor.execute("SELECT name FROM remote_db.sqlite_master WHERE type='table' AND name='daily_deals'")
        if cursor.fetchone() is None:
            print("âŒ é ç«¯è³‡æ–™åº«ä¸­æ²’æœ‰ daily_deals è¡¨ï¼Œå–æ¶ˆåŒæ­¥")
            cursor.execute("DETACH DATABASE remote_db")
            conn.close()
            return False

        # åŸ·è¡Œæ›¿æ›ï¼šå…ˆåˆªé™¤ local çš„ daily_dealsï¼Œå†å¾ remote åŒ¯å…¥
        cursor.execute("BEGIN")
        cursor.execute("DELETE FROM daily_deals")
        cursor.execute(
            "INSERT OR IGNORE INTO daily_deals (platform, title, price, url, image_url, crawl_time) SELECT platform, title, price, url, image_url, crawl_time FROM remote_db.daily_deals"
        )
        conn.commit()

        cursor.execute("DETACH DATABASE remote_db")
        conn.close()

        print("âœ… daily_deals åŒæ­¥å®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ daily_deals åŒæ­¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def auto_sync_daily_deals_if_needed(max_age_hours=1):
    """
    æª¢æŸ¥ local daily_deals æœ€æ–°çš„ crawl_timeï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œæˆ–è³‡æ–™åº«æª”æ¡ˆæœ€å¾Œä¿®æ”¹æ™‚é–“ï¼Œ
    å¦‚æœè¶…é max_age_hoursï¼Œå‰‡å¾ GitHub ä¸‹è¼‰ä¸¦åŒæ­¥ daily_dealsã€‚
    è¿”å› True å¦‚æœåŸ·è¡Œäº†åŒæ­¥ï¼ŒFalse å‰‡è¡¨ç¤ºä¸éœ€è¦æˆ–å¤±æ•—ã€‚
    """
    try:
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        local_db_path = os.path.join(project_root, 'data', 'crawler_data.db')

        latest_time = None
        if os.path.exists(local_db_path):
            try:
                conn = sqlite3.connect(local_db_path)
                cursor = conn.cursor()
                cursor.execute("SELECT MAX(crawl_time) FROM daily_deals")
                row = cursor.fetchone()
                conn.close()
                if row and row[0]:
                    # crawl_time å„²å­˜ç‚º ISO æ ¼å¼å­—ä¸²ï¼Œå˜—è©¦è§£æ
                    try:
                        latest_time = datetime.fromisoformat(row[0])
                    except Exception:
                        # ç„¡æ³•è§£ææ™‚é€€å›åˆ°æª”æ¡ˆä¿®æ”¹æ™‚é–“
                        latest_time = None
            except Exception:
                latest_time = None

        if latest_time is None and os.path.exists(local_db_path):
            mtime = os.path.getmtime(local_db_path)
            latest_time = datetime.fromtimestamp(mtime)

        if latest_time is None:
            print("ğŸ”„ local daily_deals ç„¡è³‡æ–™æˆ– DB ä¸å­˜åœ¨ï¼Œå°‡ç›´æ¥ä¸‹è¼‰ä¸¦åŒæ­¥ daily_deals")
            tmp = download_latest_daily_deals_db()
            if tmp:
                try:
                    res = sync_daily_deals_from_remote_db(tmp, local_db_path)
                    os.remove(tmp)
                    return res
                except Exception:
                    if os.path.exists(tmp):
                        os.remove(tmp)
                    return False
            return False

        now = datetime.now()
        age_hours = (now - latest_time).total_seconds() / 3600

        if age_hours > max_age_hours:
            print(f"ğŸ”„ daily_deals æœ€å¾Œæ›´æ–°å·² {age_hours:.1f} å°æ™‚ï¼Œé–‹å§‹å¾ GitHub åŒæ­¥ daily_deals...")
            tmp = download_latest_daily_deals_db()
            if not tmp:
                return False
            try:
                res = sync_daily_deals_from_remote_db(tmp, local_db_path)
                os.remove(tmp)
                return res
            except Exception:
                if os.path.exists(tmp):
                    os.remove(tmp)
                return False
        else:
            print(f"âœ… daily_deals è¶³å¤ æ–°ï¼ˆ{age_hours:.1f} å°æ™‚å‰ï¼‰ï¼Œç„¡éœ€åŒæ­¥")
            return False
    except Exception as e:
        print(f"âŒ auto_sync_daily_deals_if_needed å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    # æ¸¬è©¦åŠŸèƒ½
    print("ğŸ§ª æ¸¬è©¦ GitHub è³‡æ–™åº«åŒæ­¥åŠŸèƒ½...")
    check_database_update_time()
    download_latest_database()
